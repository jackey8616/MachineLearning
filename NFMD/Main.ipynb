{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "class Printer:\n",
    "    \n",
    "    def __init__(self, logFile, initTime=time.time()):\n",
    "        self.initTime = initTime\n",
    "        self.log = self.LogInit(logFile) if logFile is not None else None\n",
    "        self.Print('Printer Inited')\n",
    "    \n",
    "    def LogInit(self, filename, mode='w+'):\n",
    "        return open(filename, mode)\n",
    "    \n",
    "    def LogClose(self,):\n",
    "        self.log.close()\n",
    "    \n",
    "    def Print(self, msg, end='\\n', timeInput=True, log=True):\n",
    "        output = ' {}'.format(msg) if timeInput == False else '[{} ({:9.3f} Sec)] {}'.format(str(datetime.datetime.now()), time.time() - self.initTime, msg)\n",
    "        print(output, end=end)\n",
    "        if log:\n",
    "            self.log.write(output + end)\n",
    "        \n",
    "    def PrintKnownPredictReport(self, true, predict):\n",
    "        accuracy = metrics.accuracy_score(true, predict)\n",
    "        self.Print('Accuracy: ', end='')\n",
    "        self.Print(accuracy, timeInput=False)\n",
    "        accuracyNor = metrics.accuracy_score(true, predict, normalize=False)\n",
    "        self.Print('Accuracy(Sameples):', end='')\n",
    "        self.Print(accuracyNor, timeInput=False)\n",
    "\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(true, predict)\n",
    "        self.Print('ROC curve:')\n",
    "        self.Print('-- TPR = TP / (TP + FN): ', end='')\n",
    "        self.Print(tpr, timeInput=False)\n",
    "        self.Print('-- FPR = FP / (FP + TN): ', end='')\n",
    "        self.Print(fpr, timeInput=False)\n",
    "        self.Print('-- Thresholds: ', end='')\n",
    "        self.Print(thresholds, timeInput=False)\n",
    "\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        self.Print('AUC: ', end='')\n",
    "        self.Print(auc, timeInput=False)\n",
    "        \n",
    "    def DrawScatter(self, X, Y, Z, C, xlabel, ylabel, zlabel, figsize=(8, 6), dpi=400):\n",
    "        fig = plg.figure(figsize=figsize, dpi=dpi)\n",
    "        ax = Axes3D(fig)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_zlabel(zlabel)\n",
    "        ax.scatter(X, Y, Z, C)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join, isfile, isdir\n",
    "import pandas as pd\n",
    "\n",
    "class Filer:\n",
    "    \n",
    "    def __init__(self, printer):\n",
    "        self.printer = printer\n",
    "        self.printer.Print('Filer Inited.')\n",
    "    \n",
    "    def getFiles(self, filePath):\n",
    "        files = []\n",
    "        if(isfile(filePath)):\n",
    "            return [filePath]\n",
    "        for f in listdir(filePath):\n",
    "            if isfile(join(filePath, f)):\n",
    "                files.append(join(filePath, f))\n",
    "            elif isdir(join(filePath, f)):\n",
    "                files.extend(self.getFiles(join(filePath, f)))\n",
    "        return files\n",
    "    \n",
    "    def concatFiles(self, filesPath, dropDupSet=None):\n",
    "        self.printer.Print('Concating files from path: %s' % filesPath)\n",
    "        if dropDupSet is not None:\n",
    "            self.printer.Print('Rows will be droped base on duplicate field check: %s' % str(dropDupSet))\n",
    "        folder = filesPath\n",
    "        files = self.getFiles(filesPath)\n",
    "        colDataNames = ['FileID', 'CustomerID', 'QueryTS', 'ProductID']\n",
    "        colVirNames = ['FileID', 'VirusRate']\n",
    "        count = 0\n",
    "        \n",
    "        _data = pd.DataFrame()\n",
    "        for filename in files:\n",
    "            self.printer.Print('- (File %d) %s concating...' %  (count + 1, filename))\n",
    "            _read = pd.read_csv(filename, names=colDataNames, dtype={'FileID': str, 'CustomerID': str, 'ProductID': str})\n",
    "            _data = pd.concat([_data, _read], axis=0)\n",
    "            if dropDupSet is not None:\n",
    "                beforeDropLen = len(_data)\n",
    "                _data = _data.drop_duplicates(subset=dropDupSet)\n",
    "                self.printer.Print('--- After concate, original length: %d, after drop length: %s.' % (beforeDropLen, len(_data)))\n",
    "            del _read\n",
    "            self.printer.Print('- %s done.' % filename)\n",
    "            count += 1\n",
    "        self.printer.Print('Files concated.')\n",
    "        return _data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "logFile = './logs/SkLogisticReg_log_%s.log' % str(time.time())\n",
    "printer = Printer(logFile)\n",
    "filer = Filer(printer=printer)\n",
    "\n",
    "#_data = filer.concatFiles('./data/train_data.csv', dropDupSet=['FileID', 'CustomerID', 'ProductID']) # Read whole data\n",
    "_data = filer.concatFiles('./data/train_data/_03/0301.csv', dropDupSet=['FileID', 'CustomerID', 'ProductID']) # Read whole data\n",
    "_train_set = pd.read_csv('./data/training-set.csv', names=['FileID', 'VirusRate'], dtype={'FileID': str, 'VirusRate': float}) # Read sets VirusRate filed file.\n",
    "excTrain = pd.read_csv('./data/exception/exception_train.txt', names=['FileID']) # Read excepted data\n",
    "_data = pd.merge(_data, _train_set, how='left', on='FileID') # Merge with set.csv VirusRate field\n",
    "df = _data.loc[pd.merge(_data, excTrain, how='left', on='FileID', indicator=True)['_merge'] == 'left_only'] # Remove excepted data\n",
    "\n",
    "#df.CustomerID = LabelEncoder().fit_transform(df.CustomerID)\n",
    "a = MinMaxScaler().fit_transform(df.QueryTS.values.reshape(len(df.QueryTS), 1))\n",
    "print(a)\n",
    "dummyProductID = pd.get_dummies(df.ProductID)\n",
    "df = df.drop('ProductID', axis=1)\n",
    "df = df.join(dummyProductID)\n",
    "\n",
    "print(df.head())\n",
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
    "values = array(data)\n",
    "print(values)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 61942383 entries, 0 to 61942382\n",
    "Data columns (total 5 columns):\n",
    "FileID        object\n",
    "CustomerID    object\n",
    "QueryTS       int64\n",
    "ProductID     object\n",
    "VirusRate     float64\n",
    "dtypes: float64(1), int64(1), object(3)\n",
    "memory usage: 15.3 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, linear_model, metrics\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.utils import multiclass\n",
    "\n",
    "trainBool = False\n",
    "testBool = True\n",
    "modelFile = './model_saves/Sklearn/SkLogisticReg.pkl'\n",
    "logFile = './logs/SkLogisticReg_log_%s.log' % str(time.time())\n",
    "printer = Printer(logFile)\n",
    "filer = Filer(printer=printer)\n",
    "\n",
    "if trainBool:\n",
    "    _data03 = filer.concatFiles('./data/train_data/_04/')\n",
    "    _train = pd.read_csv('./data/training-set.csv', names=['FileID', 'VirusRate'], dtype={'FileID': str, 'VirusRate': float})\n",
    "    excTrain = pd.read_csv('./data/exception/exception_train.txt', names=['FileID'])\n",
    "    _train = _train.loc[pd.merge(_train, excTrain, how='left', on='FileID', indicator=True)['_merge'] == 'left_only']\n",
    "    df = pd.merge(_data03.copy(True), _train, how='left', on='FileID')\n",
    "    df = df[df.VirusRate.notnull()]\n",
    "    dfOrigin = df.copy(True)\n",
    "\n",
    "if testBool:\n",
    "    _data04 = filer.concatFiles('./data/train_data/_05/')\n",
    "    #_test = pd.read_csv('./data/testing-set.csv', names=['FileID', 'VirusRate'], dtype={'FileID': str, 'VirusRate': float})\n",
    "    _train = pd.read_csv('./data/training-set.csv', names=['FileID', 'VirusRate'], dtype={'FileID': str, 'VirusRate': float})\n",
    "    excTrain = pd.read_csv('./data/exception/exception_train.txt', names=['FileID'])\n",
    "    _train = _train.loc[pd.merge(_train, excTrain, how='left', on='FileID', indicator=True)['_merge'] == 'left_only']\n",
    "    df2 = pd.merge(_data04.copy(True), _train, how='left', on='FileID')\n",
    "    df2.VirusRate.fillna(float(0.0), inplace=True)\n",
    "    df2Origin = df2.copy(True)\n",
    "    \n",
    "if trainBool:\n",
    "    df.CustomerID = LabelEncoder().fit_transform(df.CustomerID)\n",
    "    df.ProductID = LabelEncoder().fit_transform(df.ProductID)\n",
    "    #train_X, test_X, train_y, test_y = train_test_split(df.drop(labels=['FileID', 'VirusRate'], axis=1), df.VirusRate, test_size=0.1)\n",
    "    train_X = df.drop(labels=['FileID', 'VirusRate'], axis=1)\n",
    "    train_y = df.VirusRate\n",
    "\n",
    "if testBool:\n",
    "    df2.CustomerID = LabelEncoder().fit_transform(df2.CustomerID)\n",
    "    df2.ProductID = LabelEncoder().fit_transform(df2.ProductID)\n",
    "    test_X = df2.drop(labels=['FileID', 'VirusRate'], axis=1)\n",
    "    test_y = df2.VirusRate\n",
    "\n",
    "#logistic = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "logistic = linear_model.LogisticRegression(solver='sag')\n",
    "logistic = joblib.load(modelFile) if isfile(modelFile) else logistic\n",
    "printer.Print('Model inited.')\n",
    "if trainBool:\n",
    "    printer.Print('Training...')\n",
    "    logistic_model = logistic.fit(train_X, train_y)\n",
    "    joblib.dump(logistic, modelFile)\n",
    "    printer.Print('Model saved.')\n",
    "    \n",
    "if testBool:\n",
    "    printer.Print('Predicting...')\n",
    "    logistic_model = logistic\n",
    "    test_y_predict = logistic_model.predict(test_X)\n",
    "    test_y_proba = logistic_model.predict_proba(test_X)\n",
    "    dfVirusRate = pd.DataFrame({'VirusRate': test_y_proba[:,:1].flatten()})\n",
    "    whole = pd.merge(test_X, dfVirusRate, left_index=True, right_index=True)\n",
    "    \n",
    "    printer.Print('Coef: ', end='')\n",
    "    printer.Print(logistic_model.coef_, timeInput=False)\n",
    "    printer.Print('Intercept: ', end='')\n",
    "    printer.Print(logistic_model.intercept_, timeInput=False)\n",
    "    printer.Print('Predict: ', end='')\n",
    "    printer.Print(test_y_predict, timeInput=False)\n",
    "    printer.Print('')\n",
    "    printer.Print('Whole:', timeInput=False)\n",
    "    printer.Print(whole, timeInput=False)\n",
    "\n",
    "    printer.PrintKnownPredictReport(test_y, test_y_predict)\n",
    "\n",
    "printer.Print('Done')\n",
    "printer.LogClose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "logFile = './logs/SkLogisticReg_log_%s.log' % str(time.time())\n",
    "printer = Printer(logFile)\n",
    "filer = Filer(printer=printer)\n",
    "\n",
    "_data05 = filer.concatFiles('./data/train_data/_05/')\n",
    "_train = pd.read_csv('./data/training-set.csv', names=['FileID', 'VirusRate'], dtype={'FileID': str, 'VirusRate': float})\n",
    "excTrain = pd.read_csv('./data/exception/exception_train.txt', names=['FileID'])\n",
    "_train = _train.loc[pd.merge(_train, excTrain, how='left', on='FileID', indicator=True)['_merge'] == 'left_only']\n",
    "df = pd.merge(_data05.copy(True), _train, how='left', on='FileID')\n",
    "df = df[df.VirusRate.notnull()]\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
