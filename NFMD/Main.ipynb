{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "class Printer:\n",
    "    \n",
    "    def __init__(self, logFile, initTime=time.time()):\n",
    "        self.initTime = initTime\n",
    "        self.log = self.LogInit(logFile) if logFile is not None else None\n",
    "        self.Print('Printer Inited')\n",
    "    \n",
    "    def LogInit(self, filename, mode='w+'):\n",
    "        return open(filename, mode)\n",
    "    \n",
    "    def LogClose(self,):\n",
    "        self.log.close()\n",
    "    \n",
    "    def Print(self, msg, end='\\n', timeInput=True, log=True):\n",
    "        output = ' {}'.format(msg) if timeInput == False else '[{} ({:9.3f} Sec)] {}'.format(str(datetime.datetime.now()), time.time() - self.initTime, msg)\n",
    "        print(output, end=end)\n",
    "        if log:\n",
    "            self.log.write(output + end)\n",
    "        \n",
    "    def PrintJudgeResult(self, true, predict):\n",
    "        accuracy = metrics.accuracy_score(true, predict)\n",
    "        self.Print('Accuracy: ', end='')\n",
    "        self.Print(accuracy, timeInput=False)\n",
    "        accuracyNor = metrics.accuracy_score(true, predict, normalize=False)\n",
    "        self.Print('Accuracy(Sameples):', end='')\n",
    "        self.Print(accuracyNor, timeInput=False)\n",
    "\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(true, predict)\n",
    "        self.Print('ROC curve:')\n",
    "        self.Print('-- TPR = TP / (TP + FN): ', end='')\n",
    "        self.Print(tpr, timeInput=False)\n",
    "        self.Print('-- FPR = FP / (FP + TN): ', end='')\n",
    "        self.Print(fpr, timeInput=False)\n",
    "        self.Print('-- Thresholds: ', end='')\n",
    "        self.Print(thresholds, timeInput=False)\n",
    "\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        self.Print('AUC: ', end='')\n",
    "        self.Print(auc, timeInput=False)\n",
    "        \n",
    "    def DrawScatter(self, X, Y, Z, C, xlabel, ylabel, zlabel, figsize=(8, 6), dpi=400):\n",
    "        fig = plg.figure(figsize=figsize, dpi=dpi)\n",
    "        ax = Axes3D(fig)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_zlabel(zlabel)\n",
    "        ax.scatter(X, Y, Z, C)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join, isfile, isdir\n",
    "import pandas as pd\n",
    "\n",
    "class Filer:\n",
    "    \n",
    "    def __init__(self, printer):\n",
    "        self.printer = printer\n",
    "        self.printer.Print('Filer Inited.')\n",
    "    \n",
    "    def getFiles(self, filePath):\n",
    "        files = []\n",
    "        if(isfile(filePath)):\n",
    "            return [filePath]\n",
    "        for f in listdir(filePath):\n",
    "            if isfile(join(filePath, f)):\n",
    "                files.append(join(filePath, f))\n",
    "            elif isdir(join(filePath, f)):\n",
    "                files.extend(self.getFiles(join(filePath, f)))\n",
    "        return files\n",
    "    \n",
    "    def concatFiles(self, filesPath):\n",
    "        self.printer.Print('Concating files from path: %s' % filesPath)\n",
    "        folder = filesPath\n",
    "        files = self.getFiles(filesPath)\n",
    "        colDataNames = ['FileID', 'CustomerID', 'QueryTS', 'ProductID']\n",
    "        colVirNames = ['FileID', 'VirusRate']\n",
    "        count = 0\n",
    "        \n",
    "        _data = pd.DataFrame()\n",
    "        for filename in files:\n",
    "            self.printer.Print('-- (File %d) %s concating...' %  (count + 1, filename), end='')\n",
    "            _read = pd.read_csv(filename, names=colDataNames, dtype={'FileID': str, 'CustomerID': str, 'ProductID': str})\n",
    "            _data = pd.concat([_data, _read], axis=0)\n",
    "            del _read\n",
    "            self.printer.Print('%s down.' % filename, timeInput=False)\n",
    "            count += 1\n",
    "        self.printer.Print('Files concated.')\n",
    "        return _data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-02-01 06:56:20.118283 ( 1398.546 Sec)] Printer Inited\n",
      "[2018-02-01 06:56:20.119319 ( 1398.547 Sec)] Filer Inited.\n",
      "[2018-02-01 06:56:20.119596 ( 1398.547 Sec)] Concating files from path: ./data/train_data/_03/\n",
      "[2018-02-01 06:56:20.242206 ( 1398.670 Sec)] -- (File 1) ./data/train_data/_03/0322.csv concating..."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, linear_model, metrics\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "trainBool = True\n",
    "testBool = False\n",
    "modelFile = './model_saves/Sklearn/SkLogisticReg.pkl'\n",
    "logFile = './logs/SkLogisticReg_log_%s.log' % str(time.time())\n",
    "printer = Printer(logFile)\n",
    "filer = Filer(printer=printer)\n",
    "\n",
    "if trainBool:\n",
    "    _data03 = filer.concatFiles('./data/train_data/_03/')\n",
    "    _train = pd.read_csv('./data/training-set.csv', names=['FileID', 'VirusRate'], dtype={'FileID': str, 'VirusRate': float})\n",
    "    excTrain = pd.read_csv('./data/exception/exception_train.txt', names=['FileID'])\n",
    "    _train = train.loc[pd.merge(train, excTrain, how='left', on='FileID', indicator=True)['_merge'] == 'left_only']\n",
    "    df = pd.merge(_data03.copy(True), _train, how='left', on='FileID')\n",
    "    df = df[df.VirusRate.notnull()]\n",
    "    dfOrigin = df.copy(True)\n",
    "\n",
    "if testBool:\n",
    "    _data04 = filer.concatFiles('./data/train_data/_04/')\n",
    "    #_test = pd.read_csv('./data/testing-set.csv', names=['FileID', 'VirusRate'], dtype={'FileID': str, 'VirusRate': float})\n",
    "    _train = pd.read_csv('./data/training-set.csv', names=['FileID', 'VirusRate'], dtype={'FileID': str, 'VirusRate': float})\n",
    "    excTrain = pd.read_csv('./data/exception/exception_train.txt', names=['FileID'])\n",
    "    _train = train.loc[pd.merge(train, excTrain, how='left', on='FileID', indicator=True)['_merge'] == 'left_only']\n",
    "    df2 = pd.merge(_data04.copy(True), _train, how='left', on='FileID')\n",
    "    df2Origin = df2.copy(True)\n",
    "\n",
    "if trainBool:\n",
    "    df.CustomerID = LabelEncoder().fit_transform(df.CustomerID)\n",
    "    df.ProductID = LabelEncoder().fit_transform(df.ProductID)\n",
    "    #train_X, test_X, train_y, test_y = train_test_split(df.drop(columns=['FileID', 'VirusRate']), df.VirusRate, test_size=0.1)\n",
    "    train_X = df.drop(columns=['FileID', 'VirusRate'])\n",
    "    train_y = df.VirusRate\n",
    "\n",
    "if testBool:\n",
    "    df2.CustomerID = LabelEncoder().fit_transform(df2.CustomerID)\n",
    "    df2.ProductID = LabelEncoder().fit_transform(df2.ProductID)\n",
    "    test_X = df2.drop(columns=['FileID', 'VirusRate'])\n",
    "    test_y = df2.VirusRate\n",
    "\n",
    "#logistic = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "logistic = linear_model.LogisticRegression(solver='sag')\n",
    "logistic = joblib.load(modelFile) if isfile(modelFile) else logistic\n",
    "printer.Print('Model inited.')\n",
    "if trainBool:\n",
    "    printer.Print('Training...')\n",
    "    logistic_model = logistic.fit(train_X, train_y)\n",
    "    joblib.dump(logistic, modelFile)\n",
    "    printer.Print('Model saved.')\n",
    "    \n",
    "if testBool:\n",
    "    logistic_model = logistic\n",
    "    test_y_predict = logistic_model.predict(test_X)\n",
    "    test_y_proba = logistic_model.predict_proba(test_X)\n",
    "    dfVirusRate = pd.DataFrame({'VirusRate': test_y_proba[:,:1].flatten()})\n",
    "    whole = pd.merge(test_X, dfVirusRate, left_index=True, right_index=True)\n",
    "\n",
    "    printer.Print('Coef: ', end='')\n",
    "    printer.Print(logistic_model.coef_, timeInput=False)\n",
    "    printer.Print('Intercept: ', end='')\n",
    "    printer.Print(logistic_model.intercept_, timeInput=False)\n",
    "    printer.Print('Predict: ', end='')\n",
    "    printer.Print(test_y_predict, timeInput=False)\n",
    "    printer.Print('')\n",
    "    printer.Print('Whole:', timeInput=False)\n",
    "    printer.Print(whole, timeInput=False)\n",
    "\n",
    "    printer.PrintJudgeResult(test_y, test_y_predict)\n",
    "\n",
    "printer.Print('Done')\n",
    "printer.LogClose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join, isfile, isdir\n",
    "import time, datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import preprocessing, linear_model, metrics\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "initTime = time.time()\n",
    "def overridePrint(msg, end='\\n', timeInput=True):\n",
    "    print(' {}'.format(msg) if timeInput == False else '[{} ({:9.3f} Sec)] {}'.format(str(datetime.datetime.now()), time.time() - initTime, msg), end=end)\n",
    "\n",
    "def getFiles(filePath):\n",
    "    files = []\n",
    "    if(isfile(filePath)):\n",
    "        return [filePath]\n",
    "    for f in listdir(filePath):\n",
    "        if isfile(join(filePath, f)):\n",
    "            files.append(join(filePath, f))\n",
    "        elif isdir(join(filePath, f)):\n",
    "            files.extend(getFiles(join(filePath, f)))\n",
    "    return files\n",
    "\n",
    "modelFile = './model_saves/Sklearn/SkLogisticReg.pkl'\n",
    "\n",
    "overridePrint('Inited...')\n",
    "folder = './data/train_data/_05/'\n",
    "files = getFiles(folder)\n",
    "columns = ['FileID', 'CustomerID', 'QueryTS', 'ProductID']\n",
    "count = 0\n",
    "_data = pd.DataFrame()\n",
    "overridePrint('Processing Path: %s' % folder)\n",
    "overridePrint('Loading %d files: ' % len(files))\n",
    "for filename in files:\n",
    "    overridePrint('-- (File %d) %s concating...' %  (count + 1, filename), end='')\n",
    "    _read = pd.read_csv(filename, names=columns, dtype={'FileID': str, 'CustomerID': str, 'ProductID': str})\n",
    "    _data = pd.concat([_data, _read], axis=0)\n",
    "    del _read\n",
    "    overridePrint('%s down.' % filename, timeInput=False)\n",
    "    count += 1\n",
    "\n",
    "_test = pd.read_csv('./data/testing-set.csv', names=['FileID', 'VirusRate'], dtype={'FileID': str, 'VirusRate':float})\n",
    "df = pd.merge(_data.copy(True), _test, how='left', on='FileID')\n",
    "df = df[df.VirusRate.notnull()]\n",
    "dfOrigin = df.copy(True)\n",
    "\n",
    "df.CustomerID = LabelEncoder().fit_transform(df.CustomerID)\n",
    "#df.CustomerID = preprocessing.minmax_scale(df.CustomerID, feature_range=(0, 1))\n",
    "df.QueryTS = preprocessing.minmax_scale(df.QueryTS, feature_range=(0, 1))\n",
    "df.ProductID = LabelEncoder().fit_transform(df.ProductID)\n",
    "#df.ProductID = preprocessing.minmax_scale(df.ProductID, feature_range=(0, 1))\n",
    "\n",
    "test_X = df\n",
    "test_y = df.VirusRate\n",
    "\n",
    "logistic = linear_model.LogisticRegression(solver='sag')\n",
    "logistic = joblib.load(modelFile) if isfile(modelFile) else logistic\n",
    "logistic_model = logistic\n",
    "test_y_predict = logistic_model.predict(df.drop(columns=['FileID', 'VirusRate']))\n",
    "test_y_proba = logistic_model.predict_proba(df.drop(columns=['FileID', 'VirusRate']))\n",
    "dfVirusRate = pd.DataFrame({'VirusRate': test_y_proba[:,:1].flatten()})\n",
    "whole = pd.merge(test_X.drop(columns=['VirusRate']), dfVirusRate, left_index=True, right_index=True)\n",
    "\n",
    "print(logistic_model.coef_)\n",
    "print(logistic_model.intercept_ )\n",
    "print(test_y_predict)\n",
    "print(test_y_proba)\n",
    "print('Whole')\n",
    "print(whole)\n",
    "\n",
    "#accuracy = metrics.accuracy_score(test_y, test_y_predict)\n",
    "#print(accuracy)\n",
    "whole.drop(columns=['CustomerID', 'QueryTS', 'ProductID']).to_csv('./result/sklearn_result.csv', sep=',', index=False)\n",
    "\n",
    "print('Done')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
